{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1beaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d3d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punting1.csv\n",
      "punting10.csv\n",
      "punting2.csv\n",
      "punting3.csv\n",
      "punting4.csv\n",
      "punting5.csv\n",
      "punting6.csv\n",
      "punting7.csv\n",
      "punting8.csv\n",
      "punting9.csv\n"
     ]
    }
   ],
   "source": [
    "punt_path=r\"C:\\Users\\91897\\Desktop\\cleaned\"\n",
    "for files_punt in os.listdir(punt_path):\n",
    "    print(files_punt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "776347be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  punting_Yds  punting_Avg  Total_Punts  punting_Lg  punting_TB  \\\n",
      "Team                                                                        \n",
      "ALA   2009         2407         41.5           58         0.0         0.0   \n",
      "ARK   2009         2359         38.7           61         0.0         0.0   \n",
      "AUB   2009         2612         40.8           64         0.0         0.0   \n",
      "KY    2009         2557         40.0           64         0.0         0.0   \n",
      "LSU   2009         1876         39.9           47         0.0         0.0   \n",
      "...    ...          ...          ...          ...         ...         ...   \n",
      "SCAR  2017         2390         43.5           55        73.0         4.0   \n",
      "TAMU  2017         3776         45.5           83        64.0         6.0   \n",
      "TENN  2017         3323         47.5           70        72.0         5.0   \n",
      "UGA   2017         2744         45.0           61        61.0         4.0   \n",
      "VAN   2017         2575         40.2           64        56.0         4.0   \n",
      "\n",
      "      punting_In20  punting_Blk  punting_Net  punting_Ret  punting_RYds  \n",
      "Team                                                                     \n",
      "ALA            0.0            0          NaN          0.0           0.0  \n",
      "ARK            0.0            0          NaN          0.0           0.0  \n",
      "AUB            0.0            0          NaN          0.0           0.0  \n",
      "KY             0.0            0          NaN          0.0           0.0  \n",
      "LSU            0.0            0          NaN          0.0           0.0  \n",
      "...            ...          ...          ...          ...           ...  \n",
      "SCAR          15.0            0         40.5         15.0          84.0  \n",
      "TAMU          26.0            1         41.8         18.0         146.0  \n",
      "TENN          28.0            0         43.0         29.0         216.0  \n",
      "UGA           26.0            0         42.0         17.0         101.0  \n",
      "VAN           14.0            0         36.5         16.0         161.0  \n",
      "\n",
      "[126 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dfs1 = []\n",
    "\n",
    "for files_punt in os.listdir(punt_path):\n",
    "    if files_punt.endswith('.csv'):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df1 = pd.read_csv(os.path.join(punt_path,files_punt))\n",
    "        column_name = 'Player'\n",
    "        df1 = df1.drop(columns=['Player'])\n",
    "        \n",
    "        # Remove leading and trailing spaces from column names\n",
    "        df1.columns = df1.columns.str.strip()\n",
    "        \n",
    "        # Group by Team and aggregate the data\n",
    "        grouped1 = df1.groupby(['Team']).agg({\n",
    "            'year': 'first',\n",
    "            'Yds': 'sum',\n",
    "            'Avg': 'mean',\n",
    "            'Punts': 'sum',\n",
    "            'Lg': 'sum',\n",
    "            'TB': 'sum',\n",
    "            'In20': 'sum',\n",
    "            'Blk': 'sum',\n",
    "            'Net': 'mean',\n",
    "            'Ret': 'sum',\n",
    "            'RYds': 'sum'\n",
    "        }) \n",
    "        grouped1['Avg'] = grouped1['Avg'].round(2)\n",
    "        \n",
    "        # Rename the columns for clarity\n",
    "        grouped1.columns = [\n",
    "            'year',\n",
    "            'punting_Yds',\n",
    "            'punting_Avg',\n",
    "            'Total_Punts',\n",
    "            'punting_Lg',\n",
    "            'punting_TB',\n",
    "            'punting_In20',\n",
    "            'punting_Blk',\n",
    "            'punting_Net',\n",
    "            'punting_Ret',\n",
    "            'punting_RYds'\n",
    "        ]\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs1.append(grouped1)\n",
    "\n",
    "combined_df1 = pd.concat(dfs1, ignore_index=False)\n",
    "print(combined_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d5a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECEIVING1.csv\n",
      "RECEIVING10.csv\n",
      "RECEIVING2.csv\n",
      "RECEIVING3.csv\n",
      "RECEIVING4.csv\n",
      "RECEIVING5.csv\n",
      "RECEIVING6.csv\n",
      "RECEIVING7.csv\n",
      "RECEIVING8.csv\n",
      "RECEIVING9.csv\n"
     ]
    }
   ],
   "source": [
    "receiving_path=r\"C:\\Users\\91897\\Desktop\\cleaned_receiving\"\n",
    "for files_rec in os.listdir(receiving_path):\n",
    "    print(files_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1429ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  receiving_Rec  receiving_Yds  receiving_Avg  receiving_Lg  \\\n",
      "Team                                                                    \n",
      "ALA   2009            194           2435          11.68           0.0   \n",
      "ARK   2009            217           3424          14.38           0.0   \n",
      "AUB   2009            186           2428          11.86           0.0   \n",
      "FLA   2009            232           3090          11.86           0.0   \n",
      "KY    2009            152           1548           9.57           0.0   \n",
      "...    ...            ...            ...            ...           ...   \n",
      "SCAR  2017            223           2614          10.94         314.0   \n",
      "TAMU  2017            229           3028          12.55         381.0   \n",
      "TENN  2017            132           1541          11.82         219.0   \n",
      "UGA   2017            139           2148          14.82         263.0   \n",
      "VAN   2017            192           2501          13.01         243.0   \n",
      "\n",
      "      receiving_TD  \n",
      "Team                \n",
      "ALA             17  \n",
      "ARK             27  \n",
      "AUB             21  \n",
      "FLA             23  \n",
      "KY              10  \n",
      "...            ...  \n",
      "SCAR            18  \n",
      "TAMU            22  \n",
      "TENN             9  \n",
      "UGA             20  \n",
      "VAN             24  \n",
      "\n",
      "[134 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs2 = []\n",
    "for files_rec in os.listdir(receiving_path):\n",
    "        if files_rec.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df2 = pd.read_csv(os.path.join(receiving_path,files_rec))\n",
    "            column_name = 'Player'\n",
    "            df2 = df2.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped2 = df2.groupby('Team').agg({ 'year':'first','Rec': 'sum', 'Yds': 'sum', 'Avg':'mean','Lg':'sum','TD':'sum'})\n",
    "            grouped2['Avg'] = grouped2['Avg'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped2.columns = [ 'year','receiving_Rec', 'receiving_Yds','receiving_Avg','receiving_Lg','receiving_TD']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs2.append(grouped2)\n",
    "combined_df2 = pd.concat(dfs2, ignore_index=False)\n",
    "print(combined_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7b141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def.csv\n",
      "def10.csv\n",
      "def2.csv\n",
      "def3.csv\n",
      "def4.csv\n",
      "def5.csv\n",
      "def6.csv\n",
      "def7.csv\n",
      "def8.csv\n",
      "def9.csv\n"
     ]
    }
   ],
   "source": [
    "def_path=r\"C:\\Users\\91897\\Desktop\\cleaned_def\"\n",
    "for files_def in os.listdir(def_path):\n",
    "    print(files_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57ce6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  defense_int  defense_Yds  defense_Avg  defense_Lg  defense_TD  \\\n",
      "Team                                                                        \n",
      "ALA   2009           24          319        14.49         0.0           2   \n",
      "ARK   2009           13          222        17.41         0.0           2   \n",
      "AUB   2009           17          243         9.24         0.0           4   \n",
      "FLA   2009           20          199        11.51         0.0           3   \n",
      "KY    2009           16          258        13.81         0.0           3   \n",
      "...    ...          ...          ...          ...         ...         ...   \n",
      "SCAR  2017           14          140         9.05        98.0           2   \n",
      "TAMU  2017           10           75         7.28        74.0           2   \n",
      "TENN  2017            5          186        31.00       186.0           2   \n",
      "UGA   2017           12          173        10.10        98.0           0   \n",
      "VAN   2017            7           65         9.58        65.0           0   \n",
      "\n",
      "      defense_solo  defense_Ast  defense_Total  defense_Sack  defense_YdsL  \n",
      "Team                                                                        \n",
      "ALA            336          239            575          25.5           223  \n",
      "ARK            292          160            452           7.0            59  \n",
      "AUB            324          195            519          16.5           124  \n",
      "FLA            311          182            493          15.5           101  \n",
      "KY             178          105            283           1.5             6  \n",
      "...            ...          ...            ...           ...           ...  \n",
      "SCAR           197           60            257           5.0            28  \n",
      "TAMU           206          153            359          11.5            76  \n",
      "TENN           220          172            392           1.0             2  \n",
      "UGA            160           97            257           3.5            36  \n",
      "VAN            184          105            289           4.5            29  \n",
      "\n",
      "[134 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs3 = []\n",
    "for files_def in os.listdir(def_path):\n",
    "        if files_def.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df3 = pd.read_csv(os.path.join(def_path,files_def))\n",
    "            column_name = 'Player'\n",
    "            df3 = df3.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped3 = df3.groupby('Team').agg({ 'year':'first','Int': 'sum', 'Yds': 'sum', 'Avg':'mean','Lg':'sum','TD':'sum','Solo':'sum','Ast':'sum','Tot':'sum','Sack':'sum','YdsL':'sum'})\n",
    "            grouped3['Avg'] = grouped3['Avg'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped3.columns = [ 'year','defense_int', 'defense_Yds','defense_Avg','defense_Lg','defense_TD','defense_solo','defense_Ast','defense_Total','defense_Sack','defense_YdsL']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs3.append(grouped3)\n",
    "combined_df3 = pd.concat(dfs3, ignore_index=False)\n",
    "print(combined_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188add30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kick1.csv\n",
      "kick10.csv\n",
      "kick2.csv\n",
      "kick3.csv\n",
      "kick4.csv\n",
      "kick5.csv\n",
      "kick6.csv\n",
      "kick7.csv\n",
      "kick8.csv\n",
      "kick9.csv\n"
     ]
    }
   ],
   "source": [
    "kick_path=r\"C:\\Users\\91897\\Desktop\\cleaned_kick\"\n",
    "for files_kick in os.listdir(kick_path):\n",
    "    print(files_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b39cae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  kicking_PAT_successful  kicking_PAT_total  kicking_FG_successful  \\\n",
      "Team                                                                           \n",
      "ALA   2009                    42.0               46.0                   30.0   \n",
      "ARK   2009                    58.0               59.0                   16.0   \n",
      "AUB   2009                    54.0               54.0                   15.0   \n",
      "FLA   2009                    58.0               63.0                   22.0   \n",
      "KY    2009                    40.0               41.0                    0.0   \n",
      "...    ...                     ...                ...                    ...   \n",
      "SCAR  2017                    26.0               26.0                   14.0   \n",
      "TAMU  2017                    51.0               52.0                   18.0   \n",
      "TENN  2017                    25.0               25.0                    0.0   \n",
      "UGA   2017                    63.0               63.0                   20.0   \n",
      "VAN   2017                    39.0               40.0                    0.0   \n",
      "\n",
      "      kicking_FG_total  0-19_successful  0-19_total  20-19_successful  \\\n",
      "Team                                                                    \n",
      "ALA               36.0              0.0         0.0               0.0   \n",
      "ARK               22.0              0.0         0.0               0.0   \n",
      "AUB               16.0              0.0         0.0               0.0   \n",
      "FLA               31.0              0.0         0.0               0.0   \n",
      "KY                 0.0              0.0         0.0               0.0   \n",
      "...                ...              ...         ...               ...   \n",
      "SCAR              25.0              0.0         0.0               0.0   \n",
      "TAMU              22.0              0.0         0.0               0.0   \n",
      "TENN               0.0              0.0         0.0               0.0   \n",
      "UGA               23.0              0.0         0.0               0.0   \n",
      "VAN                0.0              0.0         0.0               0.0   \n",
      "\n",
      "      20-19_total  30-39_successful  30-39_total  40-49_successful  \\\n",
      "Team                                                                 \n",
      "ALA           0.0               0.0          0.0               0.0   \n",
      "ARK           0.0               0.0          0.0               0.0   \n",
      "AUB           0.0               0.0          0.0               0.0   \n",
      "FLA           0.0               0.0          0.0               0.0   \n",
      "KY            0.0               0.0          0.0               0.0   \n",
      "...           ...               ...          ...               ...   \n",
      "SCAR          0.0               0.0          0.0               0.0   \n",
      "TAMU          0.0               0.0          0.0               0.0   \n",
      "TENN          0.0               0.0          0.0               0.0   \n",
      "UGA           0.0               0.0          0.0               0.0   \n",
      "VAN           0.0               0.0          0.0               0.0   \n",
      "\n",
      "      40-49_total  50+_successful  50+_total  kicking_Lg  kicking_Pts  \n",
      "Team                                                                   \n",
      "ALA           0.0             0.0        0.0         0.0          133  \n",
      "ARK           0.0             0.0        0.0         0.0          106  \n",
      "AUB           0.0             0.0        0.0         0.0           99  \n",
      "FLA           0.0             0.0        0.0         0.0          124  \n",
      "KY            0.0             0.0        0.0         0.0           73  \n",
      "...           ...             ...        ...         ...          ...  \n",
      "SCAR          1.0             0.0        2.0        79.0           81  \n",
      "TAMU          1.0             0.0        0.0        52.0          105  \n",
      "TENN          0.0             0.0        0.0       100.0           70  \n",
      "UGA           0.0             0.0        0.0        74.0          127  \n",
      "VAN           0.0             0.0        1.0        42.0           49  \n",
      "\n",
      "[134 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs4 = []\n",
    "for files_kick in os.listdir(kick_path):\n",
    "        if files_kick.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df4 = pd.read_csv(os.path.join(kick_path,files_kick))\n",
    "            column_name = 'Player'\n",
    "            df4 = df4.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped4 = df4.groupby('Team').agg({ 'year':'first','PAT_successful': 'sum','PAT_total': 'sum', 'FG_successful':'sum', 'FG_total':'sum','0-19_successful':'sum','0-19_total':'sum','20-29_successful':'sum','20-29_total':'sum','30-39_successful':'sum','30-39_total':'sum','40-49_successful':'sum','40-49_total':'sum','50+_successful':'sum','50+_total':'sum','Lg':'sum','Pts':'sum'})\n",
    "            # Rename the columns for clarity\n",
    "            grouped4.columns = [ 'year','kicking_PAT_successful','kicking_PAT_total', 'kicking_FG_successful','kicking_FG_total','0-19_successful','0-19_total','20-19_successful','20-19_total','30-39_successful','30-39_total','40-49_successful','40-49_total','50+_successful','50+_total','kicking_Lg','kicking_Pts']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs4.append(grouped4)\n",
    "combined_df4 = pd.concat(dfs4, ignore_index=False)\n",
    "print(combined_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9bec0a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor1.csv\n",
      "kor10.csv\n",
      "kor2.csv\n",
      "kor3.csv\n",
      "kor4.csv\n",
      "kor5.csv\n",
      "kor6.csv\n",
      "kor7.csv\n",
      "kor8.csv\n",
      "kor9.csv\n"
     ]
    }
   ],
   "source": [
    "kor_path=r\"C:\\Users\\91897\\Desktop\\cleaned_kor\"\n",
    "for files_kor in os.listdir(kor_path):\n",
    "    print(files_kor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5967fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pas1.csv\n",
      "pas10.csv\n",
      "pas2.csv\n",
      "pas3.csv\n",
      "pas4.csv\n",
      "pas5.csv\n",
      "pas6.csv\n",
      "pas7.csv\n",
      "pas8.csv\n",
      "pas9.csv\n"
     ]
    }
   ],
   "source": [
    "pas_path=r\"C:\\Users\\91897\\Desktop\\cleaned_passing\"\n",
    "for files_pas in os.listdir(pas_path):\n",
    "    print(files_pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fbc0650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  kickoff-return_Num  kickoff-return_Yds  kickoff-return_Avg  \\\n",
      "Team                                                                     \n",
      "ALA   2009                  33                 791               15.21   \n",
      "ARK   2009                  54                1283               21.07   \n",
      "AUB   2009                  63                1493               20.45   \n",
      "FLA   2009                  40                1055               24.64   \n",
      "KY    2009                  56                1316               18.18   \n",
      "...    ...                 ...                 ...                 ...   \n",
      "SCAR  2017                  33                 713               23.44   \n",
      "TAMU  2017                  42                 905               16.57   \n",
      "TENN  2017                  32                 680               17.29   \n",
      "UGA   2017                  26                 612               14.04   \n",
      "VAN   2017                  30                 659               18.70   \n",
      "\n",
      "      kickoff-return_FC  kickoff-return_Lg  kickoff-return_TD  \n",
      "Team                                                           \n",
      "ALA                 0.0                0.0                  0  \n",
      "ARK                 0.0                0.0                  1  \n",
      "AUB                 0.0                0.0                  1  \n",
      "FLA                 0.0                0.0                  1  \n",
      "KY                  0.0                0.0                  1  \n",
      "...                 ...                ...                ...  \n",
      "SCAR                1.0              220.0                  2  \n",
      "TAMU                0.0              309.0                  1  \n",
      "TENN                0.0              198.0                  1  \n",
      "UGA                 3.0              114.0                  0  \n",
      "VAN                 0.0              112.0                  0  \n",
      "\n",
      "[134 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dfs5 = []\n",
    "\n",
    "for files_kor in os.listdir(kor_path):\n",
    "    if files_kor.endswith('.csv'):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df5 = pd.read_csv(os.path.join(kor_path, files_kor))\n",
    "        column_name = 'Player'\n",
    "        df5 = df5.drop(columns=['Player'])\n",
    "        \n",
    "        # Remove leading and trailing spaces from column names\n",
    "        df5.columns = df5.columns.str.strip()\n",
    "        \n",
    "        # Group by Team and aggregate the data\n",
    "        grouped5 = df5.groupby('Team').agg({\n",
    "            'year': 'first',\n",
    "            'Num': 'sum',\n",
    "            'Yds': 'sum',\n",
    "            'Avg': 'mean',\n",
    "            'FC': 'sum',\n",
    "            'Lg': 'sum',\n",
    "            'TD': 'sum'\n",
    "        }) \n",
    "        grouped5['Avg'] = grouped5['Avg'].round(2)\n",
    "        \n",
    "        # Rename the columns for clarity\n",
    "        grouped5.columns = [\n",
    "            'year',\n",
    "            'kickoff-return_Num',\n",
    "            'kickoff-return_Yds',\n",
    "            'kickoff-return_Avg',\n",
    "            'kickoff-return_FC',\n",
    "            'kickoff-return_Lg',\n",
    "            'kickoff-return_TD'\n",
    "        ]\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dfs5.append(grouped5)\n",
    "\n",
    "combined_df5 = pd.concat(dfs5, ignore_index=False)\n",
    "print(combined_df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "967dbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  passing_Att  passing_Cmp  passing_Pct  passing_Yds  passing_TD  \\\n",
      "Team                                                                         \n",
      "ALA   2009          346          212        45.78         2631          17   \n",
      "ARK   2009          439          247        58.45         3842          32   \n",
      "AUB   2009          363          218        56.23         2857          25   \n",
      "FLA   2009          363          249        47.60         3305          28   \n",
      "KY    2009          324          180        50.38         1824          13   \n",
      "...    ...          ...          ...          ...          ...         ...   \n",
      "SCAR  2017          395          245        31.10         2794          18   \n",
      "TAMU  2017          449          253        62.67         3266          22   \n",
      "TENN  2017          319          180        43.32         2084          11   \n",
      "UGA   2017          303          186        36.08         2653          24   \n",
      "VAN   2017          403          232        69.30         2923          27   \n",
      "\n",
      "      passing_TD%  passing_Int  passing_Int%  passing_Lg  passing_Sack  \\\n",
      "Team                                                                     \n",
      "ALA          1.30            5         12.80         0.0           0.0   \n",
      "ARK          6.50            9          3.65         0.0           0.0   \n",
      "AUB          8.33            9          6.70         0.0           0.0   \n",
      "FLA          7.10            5          0.53         0.0           0.0   \n",
      "KY           1.88           11          1.65         0.0           0.0   \n",
      "...           ...          ...           ...         ...           ...   \n",
      "SCAR         2.30           12          1.50        68.0          29.0   \n",
      "TAMU         3.43           12          1.83       163.0          29.0   \n",
      "TENN         1.63           10          1.80       158.0          35.0   \n",
      "UGA          2.05            9         13.10       100.0          22.0   \n",
      "VAN          3.77           10          0.87       100.0          19.0   \n",
      "\n",
      "      passing_Loss  passing_rate  \n",
      "Team                              \n",
      "ALA            0.0         71.88  \n",
      "ARK            0.0        135.85  \n",
      "AUB            0.0        130.43  \n",
      "FLA            0.0        119.70  \n",
      "KY             0.0        142.43  \n",
      "...            ...           ...  \n",
      "SCAR         191.0         65.35  \n",
      "TAMU         184.0        127.97  \n",
      "TENN         242.0         83.88  \n",
      "UGA          150.0         76.20  \n",
      "VAN          120.0        129.63  \n",
      "\n",
      "[134 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs6= []\n",
    "for files_pas in os.listdir(pas_path):\n",
    "        if files_pas.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df6 = pd.read_csv(os.path.join(pas_path,files_pas))\n",
    "            column_name = 'Player'\n",
    "            df6 = df6.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped6 = df6.groupby('Team').agg({'year':'first','Att':'sum','Cmp':'sum','Pct':'mean','Yds':'sum','TD':'sum','TD%':'mean','Int':'sum','Int%':'mean','Lg':'sum','Sack':'sum','Loss':'sum','Rate':'mean'})\n",
    "            grouped6['Pct'] = grouped6['Pct'].round(2)\n",
    "            grouped6['TD%'] = grouped6['TD%'].round(2)\n",
    "            grouped6['Int%'] = grouped6['Int%'].round(2)\n",
    "            grouped6['Rate'] = grouped6['Rate'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped6.columns = ['year','passing_Att','passing_Cmp','passing_Pct','passing_Yds','passing_TD','passing_TD%','passing_Int','passing_Int%','passing_Lg','passing_Sack','passing_Loss','passing_rate']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs6.append(grouped6)\n",
    "combined_df6 = pd.concat(dfs6, ignore_index=False)\n",
    "print(combined_df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad32d098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rush1.csv\n",
      "rush10.csv\n",
      "rush2.csv\n",
      "rush3.csv\n",
      "rush4.csv\n",
      "rush5.csv\n",
      "rush6.csv\n",
      "rush7.csv\n",
      "rush8.csv\n",
      "rush9.csv\n"
     ]
    }
   ],
   "source": [
    "rush_path=r\"C:\\Users\\91897\\Desktop\\cleaned_rushing\"\n",
    "for files_rush in os.listdir(rush_path):\n",
    "    print(files_rush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b963e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  rushing_Att  rushing_Gain  rushing_Loss  rushing_Yds  rushing_Avg  \\\n",
      "Team                                                                            \n",
      "ALA   2009          575          3261           179         3082         6.71   \n",
      "ARK   2009          326          1825            86         1739         5.72   \n",
      "AUB   2009          498          3001           123         2878        11.63   \n",
      "FLA   2009          538          3349           242         3107         7.68   \n",
      "KY    2009          539          2681           201         2480         4.52   \n",
      "...    ...          ...           ...           ...          ...          ...   \n",
      "SCAR  2017          393          1859           254         1605         5.97   \n",
      "TAMU  2017          472          2364           239         2125         5.93   \n",
      "TENN  2017          322          1548           109         1439         5.58   \n",
      "UGA   2017          639          4141           235         3906         5.55   \n",
      "VAN   2017          306          1438            58         1380         8.18   \n",
      "\n",
      "      rushing_Lg  rushing_TD  \n",
      "Team                          \n",
      "ALA          0.0          31  \n",
      "ARK          0.0          21  \n",
      "AUB          0.0          24  \n",
      "FLA          0.0          30  \n",
      "KY           0.0          26  \n",
      "...          ...         ...  \n",
      "SCAR       219.0          16  \n",
      "TAMU       348.0          25  \n",
      "TENN       168.0          13  \n",
      "UGA        333.0          42  \n",
      "VAN        218.0          11  \n",
      "\n",
      "[134 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs7= []\n",
    "for files_rush in os.listdir(rush_path):\n",
    "        if files_rush.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df7 = pd.read_csv(os.path.join(rush_path,files_rush))\n",
    "            column_name = 'Player'\n",
    "            df7 = df7.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped7 = df7.groupby('Team').agg({'year':'first','Att':'sum','Gain':'sum','Loss':'sum','Yds':'sum','Avg':'mean','Lg':'sum','TD':'sum'}) \n",
    "            grouped7['Avg'] = grouped7['Avg'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped7.columns = ['year','rushing_Att','rushing_Gain','rushing_Loss','rushing_Yds','rushing_Avg','rushing_Lg','rushing_TD']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs7.append(grouped7)\n",
    "combined_df7 = pd.concat(dfs7, ignore_index=False)\n",
    "print(combined_df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c70545e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puntret1.csv\n",
      "puntret10.csv\n",
      "puntret2.csv\n",
      "puntret3.csv\n",
      "puntret4.csv\n",
      "puntret5.csv\n",
      "puntret6.csv\n",
      "puntret7.csv\n",
      "puntret8.csv\n",
      "puntret9.csv\n"
     ]
    }
   ],
   "source": [
    "puntret_path=r\"C:\\Users\\91897\\Desktop\\cleaned_punt-ret\"\n",
    "for files_puntret in os.listdir(puntret_path):\n",
    "    print(files_puntret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2e6cdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  punt-return_Num  punt-return_Yds  punt-return_Avg  punt-return_FC  \\\n",
      "Team                                                                            \n",
      "ALA   2009               39              587            12.35             0.0   \n",
      "ARK   2009               14              130            11.21             0.0   \n",
      "AUB   2009               24              117             4.96             0.0   \n",
      "FLA   2009               40              300             7.57             0.0   \n",
      "KY    2009               27              338            10.11             0.0   \n",
      "...    ...              ...              ...              ...             ...   \n",
      "SCAR  2017               19              141             7.42            15.0   \n",
      "TAMU  2017               14              240            14.28            27.0   \n",
      "TENN  2017               14              112             5.69            14.0   \n",
      "UGA   2017               28              283             4.94            31.0   \n",
      "VAN   2017               16              121             8.98            17.0   \n",
      "\n",
      "      punt-return_Lg  punt-return_TD  \n",
      "Team                                  \n",
      "ALA              0.0               1  \n",
      "ARK              0.0               1  \n",
      "AUB              0.0               0  \n",
      "FLA              0.0               1  \n",
      "KY               0.0               1  \n",
      "...              ...             ...  \n",
      "SCAR            26.0               0  \n",
      "TAMU           117.0               1  \n",
      "TENN            39.0               0  \n",
      "UGA             42.0               0  \n",
      "VAN             26.0               0  \n",
      "\n",
      "[134 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs8= []\n",
    "for files_puntret in os.listdir(puntret_path):\n",
    "        if files_puntret.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df8 = pd.read_csv(os.path.join(puntret_path,files_puntret))\n",
    "            column_name = 'Player'\n",
    "            df8 = df8.drop(columns=['Player'])\n",
    "            \n",
    "            # Group by Team and aggregate the data\n",
    "            grouped8 = df8.groupby('Team').agg({'year':'first','Num':'sum','Yds':'sum','Avg':'mean','FC':'sum','Lg':'sum','TD':'sum'}) \n",
    "            grouped8['Avg'] = grouped8['Avg'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped8.columns = ['year','punt-return_Num','punt-return_Yds','punt-return_Avg','punt-return_FC','punt-return_Lg','punt-return_TD']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs8.append(grouped8)\n",
    "combined_df8 = pd.concat(dfs8, ignore_index=False)\n",
    "print(combined_df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021a2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring10.csv\n",
      "scoring4.csv\n",
      "scoring5.csv\n",
      "scoring6.csv\n",
      "scoring7.csv\n",
      "scoring8.csv\n",
      "scoring9.csv\n"
     ]
    }
   ],
   "source": [
    "scoring_path=r\"C:\\Users\\91897\\Desktop\\cleaned_scoring\"\n",
    "for files_scoring in os.listdir(scoring_path):\n",
    "    print(files_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161c82ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  scoring_pts  scoring_tot  scoring_R  scoring_P  scoring_KR  \\\n",
      "Team                                                                       \n",
      "ALA   2018.0        609.0         82.0       28.0       51.0         1.0   \n",
      "ARK   2018.0        164.0         13.0        3.0       10.0         0.0   \n",
      "AUB   2018.0        299.0         35.0       15.0       19.0         0.0   \n",
      "FLA   2018.0        347.0         41.0       20.0       19.0         0.0   \n",
      "KY    2018.0        277.0         36.0       25.0        9.0         0.0   \n",
      "...      ...          ...          ...        ...        ...         ...   \n",
      "SCAR  2017.0        242.0         29.0       10.0       17.0         2.0   \n",
      "TAMU  2017.0        387.0         47.0       23.0       22.0         1.0   \n",
      "TENN  2017.0        172.0         17.0       11.0        5.0         1.0   \n",
      "UGA   2017.0        473.0         58.0       39.0       19.0         0.0   \n",
      "VAN   2017.0        264.0         36.0       14.0       22.0         0.0   \n",
      "\n",
      "      scoring_PR  scoring_IR  scoring_FR  scoring_BK  scoring_BP  scoring_FGR  \\\n",
      "Team                                                                            \n",
      "ALA          1.0         0.0         1.0         0.0         0.0          0.0   \n",
      "ARK          0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "AUB          0.0         0.0         1.0         0.0         0.0          0.0   \n",
      "FLA          1.0         0.0         0.0         0.0         1.0          0.0   \n",
      "KY           2.0         0.0         0.0         0.0         0.0          0.0   \n",
      "...          ...         ...         ...         ...         ...          ...   \n",
      "SCAR         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "TAMU         1.0         0.0         0.0         0.0         0.0          0.0   \n",
      "TENN         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "UGA          0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "VAN          0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "\n",
      "      scoring_PAT_successful  scoring_PAT_total  scoring_FG_successful  \\\n",
      "Team                                                                     \n",
      "ALA                     75.0               81.0                   14.0   \n",
      "ARK                     29.0               29.0                   19.0   \n",
      "AUB                     44.0               44.0                   15.0   \n",
      "FLA                     50.0               50.0                   17.0   \n",
      "KY                      40.0               40.0                    0.0   \n",
      "...                      ...                ...                    ...   \n",
      "SCAR                    26.0               26.0                   14.0   \n",
      "TAMU                    51.0               52.0                   18.0   \n",
      "TENN                    25.0               25.0                    0.0   \n",
      "UGA                     63.0               63.0                   20.0   \n",
      "VAN                     39.0               40.0                    0.0   \n",
      "\n",
      "      scoring_FG_total  scoring_Conv  scoring_Saf  \n",
      "Team                                               \n",
      "ALA               18.0           0.0          0.0  \n",
      "ARK               24.0           0.0          0.0  \n",
      "AUB               25.0           0.0          0.0  \n",
      "FLA               19.0           0.0          0.0  \n",
      "KY                 0.0           0.0          0.0  \n",
      "...                ...           ...          ...  \n",
      "SCAR              25.0           0.0          0.0  \n",
      "TAMU              21.0           0.0          0.0  \n",
      "TENN               0.0           0.0          0.0  \n",
      "UGA               23.0           1.0          0.0  \n",
      "VAN                0.0           0.0          0.0  \n",
      "\n",
      "[98 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs9= []\n",
    "for files_scoring in os.listdir(scoring_path):\n",
    "        if files_scoring.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df9 = pd.read_csv(os.path.join(scoring_path,files_scoring))\n",
    "            column_name = 'Player'\n",
    "            df9 = df9.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped9 = df9.groupby('Team').agg({'year':'first','Pts': 'sum','Tot': 'sum','R': 'sum','P': 'sum','KR': 'sum','PR': 'sum','IR': 'sum','FR': 'sum','BK': 'sum','BP': 'sum','FGR': 'sum','PAT_successful': 'sum','PAT_total': 'sum','FG_successful': 'sum','FG_total': 'sum','Conv': 'sum','Saf': 'sum'}) \n",
    "            # Rename the columns for clarity\n",
    "            grouped9.columns = ['year','scoring_pts','scoring_tot','scoring_R','scoring_P','scoring_KR','scoring_PR','scoring_IR','scoring_FR','scoring_BK','scoring_BP','scoring_FGR','scoring_PAT_successful','scoring_PAT_total','scoring_FG_successful','scoring_FG_total','scoring_Conv','scoring_Saf']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs9.append(grouped9)\n",
    "combined_df9 = pd.concat(dfs9, ignore_index=False)\n",
    "print(combined_df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8bd876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kickoff10.csv\n",
      "kickoff5.csv\n",
      "kickoff6.csv\n",
      "kickoff7.csv\n",
      "kickoff8.csv\n",
      "kickoff9.csv\n"
     ]
    }
   ],
   "source": [
    "kickoff_path=r\"C:\\Users\\91897\\Desktop\\cleaned_kickoff\"\n",
    "for files_kickoff in os.listdir(kickoff_path):\n",
    "    print(files_kickoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f601c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year  kickoff_Num     kickoff_Yds  kickoff_Avg  kickoff_Lg  kickoff_TB  \\\n",
      "Team                                                                           \n",
      "ALA   2018          121         6,77454        55.25          75          44   \n",
      "ARK   2018           59           3,387        57.40          76          17   \n",
      "AUB   2018           79        4,408571        63.20          65          56   \n",
      "FLA   2018           88        5,086400        59.95          78          47   \n",
      "KY    2018           66           3,979        60.30          77          36   \n",
      "...    ...          ...             ...          ...         ...         ...   \n",
      "SCAR  2017           67       4,1726545        58.07          65          44   \n",
      "TAMU  2017           81  4,424264145123        56.22          65          34   \n",
      "TENN  2017           51        2,632636        63.90          70          33   \n",
      "UGA   2017           96        6,043128        64.15          74          67   \n",
      "VAN   2017           57        3,440130        63.75          65          38   \n",
      "\n",
      "      kickoff_OB  kickoff_Ret kickoff_RYds  kickoff_TD  \n",
      "Team                                                    \n",
      "ALA            4           41        79728           0  \n",
      "ARK            1           29          608           2  \n",
      "AUB            3           16        26051           0  \n",
      "FLA            0           34        62538           0  \n",
      "KY             0           23          419           0  \n",
      "...          ...          ...          ...         ...  \n",
      "SCAR           2           21       389420           0  \n",
      "TAMU           4           43   7356651111           1  \n",
      "TENN           1           17       267125           0  \n",
      "UGA            0           29        51155           0  \n",
      "VAN            2           17         3500           0  \n",
      "\n",
      "[84 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "dfs10= []\n",
    "for files_kickoff in os.listdir(kickoff_path):\n",
    "        if files_kickoff.endswith('.csv'):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df10 = pd.read_csv(os.path.join(kickoff_path,files_kickoff))\n",
    "            column_name = 'Player'\n",
    "            df10 = df10.drop(columns=['Player'])\n",
    "            # Group by Team and aggregate the data\n",
    "            grouped10 = df10.groupby('Team').agg({'year':'first','Num': 'sum','Yds': 'sum','Avg': 'mean','Lg': 'max','TB': 'sum','OB': 'sum','Ret': 'sum','RYds': 'sum','TD': 'sum'})\n",
    "            grouped10['Avg'] = grouped10['Avg'].round(2)\n",
    "            # Rename the columns for clarity\n",
    "            grouped10.columns = ['year','kickoff_Num','kickoff_Yds','kickoff_Avg','kickoff_Lg','kickoff_TB','kickoff_OB','kickoff_Ret','kickoff_RYds','kickoff_TD']\n",
    "            # Append the DataFrame to the list\n",
    "            dfs10.append(grouped10)\n",
    "combined_df10 = pd.concat(dfs10, ignore_index=False)\n",
    "print(combined_df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5840d5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             punting_Yds  punting_Avg  Total_Punts  punting_Lg  punting_TB  \\\n",
      "Team year                                                                    \n",
      "ALA  2009.0       2407.0         41.5         58.0         0.0         0.0   \n",
      "     2010.0       1607.0         39.2         41.0         0.0         0.0   \n",
      "     2011.0       1534.0         39.3         39.0         0.0         0.0   \n",
      "     2012.0       2214.0         44.3         50.0         0.0         0.0   \n",
      "     2013.0       1836.0         47.1         39.0        63.0         6.0   \n",
      "...                  ...          ...          ...         ...         ...   \n",
      "VAN  2014.0       2796.0         42.4         66.0        68.0         7.0   \n",
      "     2015.0       3234.0         40.9         79.0        78.0         3.0   \n",
      "     2016.0       2832.0         41.6         68.0        67.0         6.0   \n",
      "     2017.0       2575.0         40.2         64.0        56.0         4.0   \n",
      "     2018.0       2288.0         44.9         51.0        62.0         6.0   \n",
      "\n",
      "             punting_In20  punting_Blk  punting_Net  punting_Ret  \\\n",
      "Team year                                                          \n",
      "ALA  2009.0           0.0          0.0          0.0          0.0   \n",
      "     2010.0           0.0          0.0          0.0          0.0   \n",
      "     2011.0           0.0          0.0          0.0          0.0   \n",
      "     2012.0           0.0          0.0          0.0          0.0   \n",
      "     2013.0          15.0          1.0         41.5         13.0   \n",
      "...                   ...          ...          ...          ...   \n",
      "VAN  2014.0          19.0          0.0         38.1         22.0   \n",
      "     2015.0          27.0          0.0         34.8         28.0   \n",
      "     2016.0          22.0          2.0         36.8         18.0   \n",
      "     2017.0          14.0          0.0         36.5         16.0   \n",
      "     2018.0          19.0          0.0         40.0         16.0   \n",
      "\n",
      "             punting_RYds  ...  scoring_FG_total  scoring_Conv  scoring_Saf  \\\n",
      "Team year                  ...                                                \n",
      "ALA  2009.0           0.0  ...               0.0           0.0          0.0   \n",
      "     2010.0           0.0  ...               0.0           0.0          0.0   \n",
      "     2011.0           0.0  ...               0.0           0.0          0.0   \n",
      "     2012.0           0.0  ...               0.0           1.0          0.0   \n",
      "     2013.0          58.0  ...               0.0           0.0          0.0   \n",
      "...                   ...  ...               ...           ...          ...   \n",
      "VAN  2014.0         141.0  ...               0.0           1.0          0.0   \n",
      "     2015.0         422.0  ...               0.0           1.0          0.0   \n",
      "     2016.0         134.0  ...               0.0           0.0          0.0   \n",
      "     2017.0         161.0  ...               0.0           0.0          0.0   \n",
      "     2018.0         130.0  ...              22.0           0.0          0.0   \n",
      "\n",
      "             kickoff_Num  kickoff_Avg  kickoff_Lg  kickoff_TB  kickoff_OB  \\\n",
      "Team year                                                                   \n",
      "ALA  2009.0          0.0         0.00         0.0         0.0         0.0   \n",
      "     2010.0          0.0         0.00         0.0         0.0         0.0   \n",
      "     2011.0          0.0         0.00         0.0         0.0         0.0   \n",
      "     2012.0          0.0         0.00         0.0         0.0         0.0   \n",
      "     2013.0         90.0        63.30        65.0        22.0         0.0   \n",
      "...                  ...          ...         ...         ...         ...   \n",
      "VAN  2014.0         44.0        60.33        69.0        13.0         2.0   \n",
      "     2015.0         44.0        58.10        65.0        10.0         3.0   \n",
      "     2016.0         62.0        59.70        70.0        15.0         8.0   \n",
      "     2017.0         57.0        63.75        65.0        38.0         2.0   \n",
      "     2018.0         70.0        63.50        65.0        51.0         1.0   \n",
      "\n",
      "             kickoff_Ret  kickoff_TD  \n",
      "Team year                             \n",
      "ALA  2009.0          0.0         0.0  \n",
      "     2010.0          0.0         0.0  \n",
      "     2011.0          0.0         0.0  \n",
      "     2012.0          0.0         0.0  \n",
      "     2013.0         68.0         0.0  \n",
      "...                  ...         ...  \n",
      "VAN  2014.0         26.0         0.0  \n",
      "     2015.0         29.0         0.0  \n",
      "     2016.0         39.0         1.0  \n",
      "     2017.0         17.0         0.0  \n",
      "     2018.0         16.0         0.0  \n",
      "\n",
      "[134 rows x 96 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91897\\AppData\\Local\\Temp\\ipykernel_4008\\4116708559.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  combined151=combined1510.groupby(['Team','year']).sum()\n"
     ]
    }
   ],
   "source": [
    "combined1510=pd.concat([combined_df1,combined_df2,combined_df3,combined_df4,combined_df5,combined_df6,combined_df7,combined_df8,combined_df9,combined_df10],ignore_index=False)\n",
    "combined151=combined1510.groupby(['Team','year']).sum()\n",
    "print(combined151)\n",
    "combined151.to_csv('combined151.csv', index=True)\n",
    "combined151.to_csv('C:\\\\Users\\\\91897\\\\Downloads\\\\combined151.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
